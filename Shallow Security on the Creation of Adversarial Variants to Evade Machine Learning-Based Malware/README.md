# 归纳
## 背景调研
近二十年来，人们广泛地研究了基于机器学习检测恶意软件的技术。而近几年来，许多研究者开始研究如何利用对抗性的手段绕过基于机器学习的恶意软件检测器。

这类研究非常流行，因此Endgame的公司举办了一次公开挑战来邀请研究者绕过他们开发的三款机器学习模型。在这些模型中，有两款采用深度学习技术直接将二进制样本作为输入，而另一款通过决策树将文件的元数据作为注入。挑战者需要修改50个主办方提供的Windows平台恶意代码样本，不仅绕过检测模型，而且能够正常运行
该论文（Shallow Security: on the Creation of Adversarial Variants to Evade Machine Learning-Based Malware Detectors）作者的研究团队在2019年8月参与了这个挑战，提出了一套自动化对抗恶意样本生成技术，成功地通过了所有挑战取得了冠军，并且降低了真实的反病毒软件的检测率。

在论文中，作者详细描述了比赛时采用的技术，即一套自动将原有的恶意软件的二进制节放入资源节中，并且增加新的数据段来制造对抗样本的技术。同时作者指出了基于机器学习技术识别恶意代码的模型存在的缺陷并提出了展望。

## 技术调研
比赛模型概述
论文中提到了以下几种用于检测恶意软件的模型：

1.	MalConv模型


- 该模型是一个端到端的深度学习模型，直接学习一个不加处理的二进制文件来判定恶意代码。它将输入传入至一个8维的embedding层，接着用一个宽度为500，stride为500，filter为128的卷积层处理，然后将数据传入至包含128个单元的全连接层，最后用softmax函数处理后输出。

2. Non-Negative MalConv模型
- 该模型和MalConv结构完全一致，但是所有的权重都是非负数，因此和会学习黑白样本双方特点的MalConv不同，Non-Negative MalConv只会学习黑样本（恶意软件）的特征。

3.	LightGBM模型

- 该模型通过梯度提升决策树算法，根据PE头信息、文件大小、时间戳、调用库、字符串等元信息判定恶意代码。

最后，值得注意的是，前两个端到端的模型具有很高的误报率，把50%以上的Windows预装时自带的PE文件判定为恶意（这么屑的模型有什么存在的必要吗 

## 模型的缺陷
论文分析了如下几种攻击模型的方式

1. 增加随机数据
- 该方法通过在黑样本中增加随机数据来试图绕过模型的检测，由于竞赛限制，作者把增加数据的范围限制在了5MB以内。

- 最后的结果显示，该模型可以有效挫败MalConv模型，逃逸率高达38/50，但针对其它模型攻击效果并不明显。作者得出结论认为直接根据二进制端到端学习的模型最容易受到此类攻击的影响，而根据PE结构进行计算的模型不容易受到这样的攻击。

2. 增加白样本字符串
- 该方法通过在黑样本中随机增加白样本数据来试图绕过模型的检测。
- 最后的结果显示，该模型可以有效挫败这三种模型，其中MalConv和Non-Negative Malconv均被完全绕过，而LightGBM也有34/50的绕过率。作者得出结论，通过增加白样本字符串可以攻击所有模型，即使模型会扫描PE结构的数据。

3. 增加白样本头
- 该方法通过把黑样本中的头字段替换成白样本中的头字段。
- 但是效果并不好，逃逸率只有6/150。作者得出结论，机器应该学了其它特征导致改头的效果并不好。

4. UPX压缩
- 该方法通过UPX压缩黑样本来试图绕过模型。
- 最后的结果显示，UPX加壳效果是反向的，在作者自定义的数据集上，查杀率不降反升。作者得出结论，模型对于UPX加壳的的样本存在偏见，导致UPX加壳后更容易被杀。

5. 小众压缩壳
- 该方法通过更加小众压缩壳来试图绕过模型，在这里作者选取了TeLock壳，该壳会压缩并且加密原有的软件，使其内容无法被模型识别。
- 最后的结果显示，该方法与添加随机数据配合可以绕过所有的模型，但是存在的问题是部分样本被加壳之后无法正常执行，因此作者决定尝试别的方法。

6. 通过dropeer
- 该方法通过Dr0ph1t工具生成dropper来试图绕过模型并且不影响正常运行。
- 最后的结果显示，Dr0ph1t工具生成的dropper的确可以绕过所有的模型并且不影响正常运行，可惜的是生成的样本往往大于5MB，不符合比赛要求，作者决定尝试别的方法。
- 而我去GitHub搜索了下Dr0ph1t工具，发现工具使用pyinstaller来生成木马，而众所周知pyinstaller会把整个python解释器打包进去，这必然会大于5MB。顺便一提，该工具粗制滥造，其server端还存在命令注入漏洞，并且无法在Windows上面正常运行。

根据上述分析实验，作者得出了以下结论
1.	直接添加数据会让某些样本无法正常运行
2.	LightGBM模型在样本包含异常头和节的时候会将其视为恶意
3.	LightGBM模型可以通过加壳或者使用dropper来绕过
4.	给加壳或者使用dropper的样本添加数据不仅可以绕过MalConv类型的模型，并且还能让样本正常运行

## 针对模型进行自动化攻击
为了实现自动化地攻击这些模型，文章作者自己实现了一个dropper，在符合比赛体积限制的情况下嵌入了恶意样本，并使用Python脚本来添加正常软件中提取到的数据。

作者公开了自己的dropper的C语言代码，技术上非常简单，就是读取自身资源文件，写入一个dropper.exe并且执行。而正常软件样本采用的是Windows预装的EXE和DLL文件。

最终结果显示，所有的模型都被绕过，并且在VirusTotal上面查杀报毒结果也少了一半，作者认为攻击奏效了，并且由于真实杀毒软件也采用了基于机器学习的模型，因此对于真实杀毒软件也有效果，但是该类攻击的缺陷是生成的exe的体积变大了。


## 文章结论
根据以上研究，作者得出了以下结论
1.	端到端恶意代码检测模型容易受到直接增加数据的攻击方式。
2.	直接添加字符串并不影响PE的运行，操作系统应该对PE文件的格式进行更强的限制。
3.	当前采用的dropper+添加白样本字符串的技术生成的样本远比原样本大。
4.	需要让模型通过特征的出现而不是频率来进行判定
5.	Domain-specific 模型存在偏见并且没有真正学会一个概念(看不懂这句话
6.	需要将检测恶意软件的变体的鲁棒性作为衡量模型的一个指标
7.	应该让模型学习到具有鲁棒性的特征
8.	机器学习模型应该去学习到PE文件资源的特征
9.	把样本变成下载器也可以绕过静态检查器。作者表示自己实现了下载器，但是由于比赛环境的沙箱是断网的，因此并没有将其提交
10.	生成对抗样本也可以用于攻击

## 总结&展望

这个论文一共做了三件事，一个是做了一些实验来分析模型的弱点，第二个是提出了通过dropper+白样本数据绕过模型检测的方法，第三个是提出了一些改进意见。

但是第二件事，作为论文的核心，却显得有些马马虎虎的。
尽管作者用dropper+白样本数据取得了不错的效果，但我认为还需要补充一个实验，即dropper+随机字符串，否则的话论证不够充分（不过在[复现](https://twitter.com/drivertomtt/status/1379037207004995586)的时候，我补足了对比实验，证明了作者的论点）

除此之外，通过dropper来逃逸是不实用的办法。在真实环境中，一旦释放出原有的恶意软件，软件就会被实时扫描的反病毒软件查杀。

但是无论如何,这是我见过的少数着力分析模型缺陷的文章，在一片对机器学习+安全无脑热捧的声音中，这样的文章是非常宝贵的

